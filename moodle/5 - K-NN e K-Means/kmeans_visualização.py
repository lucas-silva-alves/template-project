# -*- coding: utf-8 -*-
"""kmeans_visualização.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NBIGyIimJjkLlClQcRpEj2nf1FkubZt_

# K-means (visualização)
"""

import os
#import ipdb # ipdb.set_trace()
import matplotlib.pyplot as plt
import numpy as np
from sklearn.cluster import KMeans

np.random.seed(0)

samples = 1000 #por grupo
# grupo artificialmente criado 1, ao redor do ponto [5,10], com desvio padrão 0.5

coordX_1 = 5+1.5*np.random.randn(samples)
coordY_1 = 5+0.5*np.random.randn(samples)

# grupo artificialmente criado 2 ao redor do ponto [2,2], com desvio padrão 0.5
coordX_2 = 4+0.5*np.random.randn(samples)
coordY_2 = 2+0.5*np.random.randn(samples)

# grupo artificialmente criado 3 ao redor do ponto [7,3], com desvio padrão 0.5
coordX_3 = 6+0.5*np.random.randn(samples)
coordY_3 = 3+0.5*np.random.randn(samples)


coordX = np.concatenate([coordX_1, coordX_2, coordX_3])
coordY = np.concatenate([coordY_1, coordY_2, coordY_3])

X = np.column_stack([coordX,coordY])


plt.scatter(X[:,0],X[:,1])
plt.show()

#ipdb.set_trace()

kmeans = KMeans(n_clusters=3, random_state=0).fit(X)

print(kmeans.labels_)
print(kmeans.cluster_centers_)




# plot the decision boundaries, based on https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html
step = 0.1
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1

xx, yy = np.meshgrid(np.arange(x_min, x_max, step), np.arange(y_min, y_max, step))

Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])

Z = Z.reshape(xx.shape)


# plotar o resultado dos clusters baseado em cor
plt.imshow(Z, interpolation='nearest',
           extent=(xx.min(), xx.max(), yy.min(), yy.max()),
           cmap=plt.cm.Paired,
           aspect='auto', origin='lower')


# plotar os dados
plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)


# plotar os centroides
centroids = kmeans.cluster_centers_

plt.plot(centroids[:,0],centroids[:,1], 'r.', markersize=10)

plt.show()

1+5*np.random.randn(10)

# Calculando o erro (inertia_)
erro_kmeans = kmeans.inertia_
print(f"Erro (Soma dos Quadrados das Distâncias): {erro_kmeans:.2f}")


def calcular_sse(X, labels, centroids):
    sse = 0
    for i, centroid in enumerate(centroids):
        cluster_points = X[labels == i]  # Pegamos os pontos do cluster i
        sse += np.sum((cluster_points - centroid) ** 2)  # Soma dos erros quadráticos
    return sse

# Obtendo rótulos e centróides do modelo treinado
labels = kmeans.labels_
centroids = kmeans.cluster_centers_

# Calculando erro manualmente
erro_manual = calcular_sse(X, labels, centroids)
print(f"Erro calculado manualmente: {erro_manual:.2f}")

# Criando o plot
plt.figure(figsize=(8, 6))
for i in range(4):
    plt.scatter(X[labels == i, 0], X[labels == i, 1], label=f'Cluster {i+1}')

# Plotando os centróides
plt.scatter(centroids[:, 0], centroids[:, 1], s=300, c='black', marker='X', label='Centroides')

plt.title("Clusters gerados pelo K-Means")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.legend()
plt.grid()
plt.show()